An Intro to Compilers
============================================================

### How to Speak to Computers, Pre-Siri


A compiler is just a program that translates other programs. Traditional compilers translate source code into executable machine code that your computer understands. (Some compilers translate source code into another programming language. These compilers are called source-to-source translators or transpilers.)Â [LLVM][7]Â is a widely used compiler project, consisting of many modular compiler tools.

Traditional compiler design comprises three parts:Â 
![](https://nicoleorchard.com/img/blog/compilers/compiler1.jpg)

*   The FrontendÂ translates source code into an intermediate representation (IR)*.Â [`clang`][1]Â is LLVMâ€™s frontend for the C family of languages.

*   The OptimizerÂ analyzes the IR and translates it into a more efficient form.Â [`opt`][2]Â is the LLVM optimizer tool.

*   The BackendÂ generates machine code by mapping the IR to the target hardware instruction set.Â [`llc`][3]Â is the LLVM backend tool.

*Â LLVM IRÂ is a low-level language that is similar to assembly. However, it abstracts away hardware-specific information.

### Hello, Compiler ğŸ‘‹

Below is a simple C program that prints â€œHello, Compiler!â€ to stdout. The C syntax is human-readable, but my computer wouldnâ€™t know what to do with it. Iâ€™m going to walk through the three compilation phases to make this program machine-executable.

```
// compile_me.c
// Wave to the compiler. The world can wait.

#include <stdio.h>

int main() {
  printf("Hello, Compiler!\n");
  return 0;
}
```

### The Frontend

As I mentioned above,Â `clang`Â is LLVMâ€™s frontend for the C family of languages. Clang consists of a C preprocessor, lexer, parser, semantic analyzer, and IR generator.

*   The C PreprocessorÂ modifies the source code before beginning the translation to IR. The preprocessor handles including external files, likeÂ `#include <stdio.h>`Â above. It will replace that line with the entire contents of theÂ `stdio.h`Â C standard library file, which will include the declaration of theÂ `printf`Â function.

     _See the output of the preprocessor step by running:_ 

    ```
    clang -E compile_me.c -o preprocessed.i

    ```

*   The LexerÂ (or scanner or tokenizer) converts a string of characters to a string of words. Each word, or token, is assigned to one of five syntactic categories: punctuation, keyword, identifier, literal, or comment.

     _Tokenization of compile_me.c_ Â 
    ![](https://nicoleorchard.com/img/blog/compilers/lexer.jpg)

*   The ParserÂ determines whether or not the stream of words consists of valid sentences in the source language. After analyzing the grammar of the token stream, it outputs an abstract syntax tree (AST). Nodes in a Clang AST represent declarations, statements, and types.

     _The AST of compile_me.c_ 

![](https://nicoleorchard.com/img/blog/compilers/tree.jpg)

*   The Semantic AnalyzerÂ traverses the AST, determining if code sentences have valid meaning. This phase checks for type errors. If the main function in compile_me.c returnedÂ `"zero"`Â instead ofÂ `0`, the semantic analyzer would throw an error becauseÂ `"zero"`Â is not of typeÂ `int`.

*   The IR GeneratorÂ translates the AST to IR.

     _Run the clang frontend on compile_me.c to generate LLVM IR:_ 

    ```
    clang -S -emit-llvm -o llvm_ir.ll compile_me.c

    ```

     _The main function in llvm_ir.ll_ 

    ```
	; llvm_ir.ll
	@.str = private unnamed_addr constant [18 x i8] c"Hello, Compiler!\0A\00", align 1

	define i32 @main() {
	  %1 = alloca i32, align 4 ; <- memory allocated on the stack
	  store i32 0, i32* %1, align 4
	  %2 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i32 0, i32 0))
	  ret i32 0
	}

	declare i32 @printf(i8*, ...)
	```

### The Optimizer

The job of the optimizer is to improve code efficiency based on its understanding of the programâ€™s runtime behavior. The optimizer takes IR as input and produces improved IR as output. LLVMâ€™s optimizer tool,Â `opt`, will optimize for processor speed with the flagÂ `-O2`Â (capital o, two) and for size with the flagÂ `-Os`Â (capital o, s).

Take a look at the difference between the LLVM IR code our frontend generated above and the result of running:

```
opt -O2 -S llvm_ir.ll -o optimized.ll

```

 _The main function in optimized.ll_ 

```
optimized.ll

@str = private unnamed_addr constant [17 x i8] c"Hello, Compiler!\00"

define i32 @main() {
  %puts = tail call i32 @puts(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @str, i64 0, i64 0))
  ret i32 0
}

declare i32 @puts(i8* nocapture readonly)

```

In the optimized version, main doesnâ€™t allocate memory on the stack, since it doesnâ€™t use any memory. The optimized code also callsÂ `puts`Â instead ofÂ `printf`because none ofÂ `printf`â€™s formatting functionality was used.

Of course, the optimizer does more than just know when to useÂ `puts`Â in lieu ofÂ `printf`. The optimizer also unrolls loops and inlines the results of simple calculations. Consider the program below, which adds two integers and prints the result.

```
// add.c
#include <stdio.h>

int main() {
  int a = 5, b = 10, c = a + b;
  printf("%i + %i = %i\n", a, b, c);
}
```

 _Here is the unoptimized LLVM IR:_ 

```
@.str = private unnamed_addr constant [14 x i8] c"%i + %i = %i\0A\00", align 1

define i32 @main() {
  %1 = alloca i32, align 4 ; <- allocate stack space for var a
  %2 = alloca i32, align 4 ; <- allocate stack space for var b
  %3 = alloca i32, align 4 ; <- allocate stack space for var c
  store i32 5, i32* %1, align 4  ; <- store 5 at memory location %1
  store i32 10, i32* %2, align 4 ; <- store 10 at memory location %2
  %4 = load i32, i32* %1, align 4 ; <- load the value at memory address %1 into register %4
  %5 = load i32, i32* %2, align 4 ; <- load the value at memory address %2 into register %5
  %6 = add nsw i32 %4, %5 ; <- add the values in registers %4 and %5\. put the result in register %6
  store i32 %6, i32* %3, align 4 ; <- put the value of register %6 into memory address %3
  %7 = load i32, i32* %1, align 4 ; <- load the value at memory address %1 into register %7
  %8 = load i32, i32* %2, align 4 ; <- load the value at memory address %2 into register %8
  %9 = load i32, i32* %3, align 4 ; <- load the value at memory address %3 into register %9
  %10 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i32 0, i32 0), i32 %7, i32 %8, i32 %9)
  ret i32 0
}

declare i32 @printf(i8*, ...)

```

 _Here is the optimized LLVM IR:_ 

```
@.str = private unnamed_addr constant [14 x i8] c"%i + %i = %i\0A\00", align 1

define i32 @main() {
  %1 = tail call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str, i64 0, i64 0), i32 5, i32 10, i32 15)
  ret i32 0
}

declare i32 @printf(i8* nocapture readonly, ...)

```

Our optimized main function is essentially lines 17 and 18 of the unoptimized version, with the variable values inlined.Â `opt`Â calculated the addition because all of the variables were constant. Pretty cool, huh?

### The Backend

LLVMâ€™s backend tool isÂ `llc`. It generates machine code from LLVM IR input in three phases:

*   Instruction selectionÂ is the mapping of IR instructions to the instruction-set of the target machine. This step uses an infinite namespace of virtual registers.

*   Register allocationÂ is the mapping of virtual registers to actual registers on your target architecture. My CPU has an x86 architecture, which is limited to 16 registers. However, the compiler will use as few registers as possible.

*   Instruction schedulingÂ is the reordering of operations to reflect the target machineâ€™s performance constraints.

 _Running this command will produce some machine code!_ 

```
llc -o compiled-assembly.s optimized.ll

```

```
_main:
	pushq	%rbp
	movq	%rsp, %rbp
	leaq	L_str(%rip), %rdi
	callq	_puts
	xorl	%eax, %eax
	popq	%rbp
	retq
L_str:
	.asciz	"Hello, Compiler!"

```

This program is x86 assembly language, which is the human readable syntax for the language my computer speaks. Someone finally understands me ğŸ™Œ

* * *

Resources

1.  [Engineering a compiler][4]

2.  [Getting Started with LLVM Core Libraries][5]

--------------------------------------------------------------------------------

via: https://nicoleorchard.com/blog/compilers

ä½œè€…ï¼š[Nicole Orchard ][a]
è¯‘è€…ï¼š[è¯‘è€…ID](https://github.com/è¯‘è€…ID)
æ ¡å¯¹ï¼š[æ ¡å¯¹è€…ID](https://github.com/æ ¡å¯¹è€…ID)

æœ¬æ–‡ç”± [LCTT](https://github.com/LCTT/TranslateProject) åŸåˆ›ç¼–è¯‘ï¼Œ[Linuxä¸­å›½](https://linux.cn/) è£èª‰æ¨å‡º

[a]:https://nicoleorchard.com/
[1]:http://clang.llvm.org/
[2]:http://llvm.org/docs/CommandGuide/opt.html
[3]:http://llvm.org/docs/CommandGuide/llc.html
[4]:https://www.amazon.com/Engineering-Compiler-Second-Keith-Cooper/dp/012088478X
[5]:https://www.amazon.com/Getting-Started-LLVM-Core-Libraries/dp/1782166920
[6]:https://twitter.com/norchard/status/864246049266958336
[7]:http://llvm.org/
