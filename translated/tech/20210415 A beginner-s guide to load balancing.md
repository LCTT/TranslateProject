[#]: subject: (A beginner's guide to load balancing)
[#]: via: (https://opensource.com/article/21/4/load-balancing)
[#]: author: (Seth Kenlon https://opensource.com/users/seth)
[#]: collector: (lujun9972)
[#]: translator: (FYJNEVERFOLLOWS)
[#]: reviewer: ( )
[#]: publisher: ( )
[#]: url: ( )

负载均衡的初学者指南
======
负载均衡就是将资源分配到某一时刻最需要它的地方。
![eight stones balancing][1]

当个人电脑刚开始发展的时候，一个家庭可能只有一台（或更少）的电脑。孩子们白天玩电脑游戏，家长们晚上在业务支撑系统上做会计、编程，或者漫游。然而，想象一下今天一个只有一台电脑的家庭，你可以预想到这样会产生什么样的冲突。每个人都同时想使用电脑，而且没有足够的键盘和鼠标让每个人都能分到。

随着计算机变得越来越普遍，IT 行业或多或少也出现了同样的情况。对服务和服务器的需求已经增长到了会因为过度使用而停滞不前的程度。幸运的是，我们现在有了负载均衡的概念来帮助我们处理需求。

### 负载均衡是什么？
负载均衡是一个通用术语，指的是为了确保高效分配所管理的资源而做的任何事情。对于 web 服务器的系统管理员来说，负载均衡通常意味着确保 web 服务器软件（例如 [Nginx][2]）配置了足够的工作节点来处理高峰时刻的来访者。换言之，如果一个网站突然变得非常受欢迎，其访问者在几分钟内增加了四倍，那么运行服务器的软件必须能够响应每个访问者，并不能让任何访问者发现服务质量下降。对于简单网址，这就像修改一行配置选项一样简单，但对于具有动态内容的复杂站点，每个用户都有多个数据库查询，这可能是一个严重的问题。

这个问题本应通过云计算解决，但当 web 应用程序遇到意外激增时，它可能会无法扩展。

在进行负载均衡时，需要记住的重要一点是，*高效地*分配资源并不一定意味着*公平地*分配资源。并非所有任务都在任何时候都需要所有可用资源。一个智能的负载均衡策略仅在需要资源时才为用户和任务提供资源。这通常是应用程序开发人员的领域，而不是 IT 基础架构的责任。异步应用程序对于确保离开计算机休息的用户不会占用服务器上的宝贵资源至关重要。

### 负载均衡是怎么工作的？
负载均衡通过跨计算节点分配工作负载来避免瓶颈。这些节点可能是数据中心中的物理服务器、云中的容器、用于边缘计算的战略性放置的服务器、复杂应用程序框架中的独立 Java 虚拟机（JVM），或在单个 Linux 服务器上运行的守护进程。

这个想法是把一个大问题分成几个小任务，并把每个任务分配给一台专用计算机。例如，对于要求用户登录的网站，该网站可能托管在服务器 A 上，而登录页面和所有随附的身份验证查找都托管在服务器 B 上。这样，新用户登录一个帐户时不会从正在使用该站点的其他用户那里窃取资源。

#### 云负载均衡
云计算使用 [容器][3]，因此通常没有单独的物理服务器来处理不同的任务（实际上，有许多单独的服务器，但它们被聚集在一起作为一个计算“大脑”）。相反，"pod" 是由几个容器创建的。当一个pod 由于其用户或任务负载而开始耗尽资源时，会生成一个相同的 pod。Pod 共享存储和网络资源，每个 pod 在创建时被分配给一个计算节点。可以根据负载需要创建或销毁 Pod，这样无论有多少用户，用户都可以体验到一致的服务质量。

#### 边缘计算

[边缘计算][4] 在负载均衡时考虑现实世界。云自然是一个分布式系统，但实际上，云的节点通常集中在几个数据中心。用户离运行云的数据中心越远，他们为获得最佳服务所必须克服的物理障碍就越多。即使有光纤连接和适当的负载均衡，位于 3000 英里外的服务器的响应时间也可能比仅 300 英里外的响应时间长。
   
边缘计算将计算节点带到云的“边缘”，试图弥合地理鸿沟，为云形成一种卫星网络，因此它也在良好的负载均衡工作中发挥了作用。

### 什么是负载均衡算法？
有许多负载均衡策略，它们的复杂性取决于所涉及的技术和需求。负载均衡不必复杂，而且从一开始就负载均衡很重要，即使在使用 [Kubernetes][5] 和 [Keepalived][6] 这样的专用软件时也是如此。

当你可以设计应用程序为它自己采取简单的预防措施时，不要依赖容器来均衡负载。如果你从一开始就将应用程序设计为模块化和临时性的，那么你将受益于通过巧妙的网络设计、容器编排和其他未来技术带来的负载均衡机会。

可以指导应用程序开发人员或网络工程师工作的一些流行算法包括：
  * 按顺序将任务分配给服务器（这通常被称为轮流调度）。
  * 将任务分配给当前最不繁忙的服务器。
  * 将任务分配给具有最佳响应时间的服务器。
  * 随机分配任务。

举个例子，在分配特别复杂的任务时，可以组合或加权这些原则以支持组中最强大的服务器。通常使用 [Orchestration][7]，这样管理员就不必为负载均衡寻找完美的算法或策略，尽管有时需要由管理员选择使用哪种负载均衡方案组合。

### 预料意料之外
负载均衡实际上并不是要确保在整个网络中均匀使用所有资源。负载均衡实际上是确保即使发生意外情况也能提供可靠的用户体验。良好的基础设施可以承受计算机崩溃、应用程序过载、网络流量冲击和用户错误。思考你的服务如何具有弹性，并从头开始相应地设计负载均衡策略。

--------------------------------------------------------------------------------

via: https://opensource.com/article/21/4/load-balancing

作者：[Seth Kenlon][a]
选题：[lujun9972][b]
译者：[FYJNEVERFOLLOWS](https://github.com/FYJNEVERFOLLOWS)
校对：[校对者ID](https://github.com/校对者ID)

本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出

[a]: https://opensource.com/users/seth
[b]: https://github.com/lujun9972
[1]: https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/water-stone-balance-eight-8.png?itok=1aht_V5V (eight stones balancing)
[2]: https://opensource.com/business/15/4/nginx-open-source-platform
[3]: https://opensource.com/resources/what-are-linux-containers
[4]: https://opensource.com/article/18/5/edge-computing
[5]: https://opensource.com/resources/what-is-kubernetes
[6]: https://www.redhat.com/sysadmin/keepalived-basics
[7]: https://opensource.com/article/20/11/orchestration-vs-automation
